{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline ETL para ingesta en base de datos relacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos librerias\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\OneDrive\\Escritorio\\Proyecto-Grupal-Google-yelp\\Sprint 2 Ingenieria de Datos\\pipeline ETL\\google\\florida_data\n",
      "finalizo cargan de datos\n"
     ]
    }
   ],
   "source": [
    "# Cambiar el directorio de trabajo al directorio donde se encuentran los archivos JSON\n",
    "%cd .\\florida_data\n",
    "\n",
    "# Obtener una lista de archivos en el directorio actual\n",
    "archivos = os.listdir()\n",
    "\n",
    "# Crear un DataFrame vacío para almacenar los datos\n",
    "df_florida = pd.DataFrame()\n",
    "\n",
    "# Iterar sobre cada archivo en la lista de archivos\n",
    "for archivo in archivos:\n",
    "    # Verificar si el archivo tiene la extensión .json\n",
    "    if archivo.endswith('.json'):\n",
    "        # Leer el archivo JSON y cargarlo en un DataFrame\n",
    "        data = pd.read_json(archivo, lines=True)\n",
    "        # Concatenar los datos del archivo al DataFrame principal\n",
    "        df_florida = pd.concat([df_florida, data], axis=0)\n",
    "print(\"finalizo cargan de datos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\sebas\\OneDrive\\Escritorio\\Proyecto-Grupal-Google-yelp\\Sprint 2 Ingenieria de Datos\\pipeline ETL\\google\\florida_data\\1.json\"\n",
    "\n",
    "# Cargar el archivo JSON en un DataFrame de Pandas\n",
    "df_florida = pd.read_json(path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chequeamos tamaño del dataset\n",
    "df_florida.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino la columna pics y resp \n",
    "df_florida = df_florida.drop(['pics','resp','name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino duplicados del df \n",
    "df_florida = df_florida.drop_duplicates()\n",
    "\n",
    "# Elimino nulos \n",
    "df_florida = df_florida.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    0\n",
      "time       0\n",
      "rating     0\n",
      "text       0\n",
      "gmap_id    0\n",
      "dtype: int64\n",
      "\n",
      "Duplicados:  0\n"
     ]
    }
   ],
   "source": [
    "# Verifico nulos\n",
    "print(df_florida.isnull().sum())\n",
    "\n",
    "# Verifico duplicados\n",
    "print(\"\\nDuplicados: \",df_florida.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_16648\\3902782551.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_florida['time_normalizado'] = pd.to_datetime(df_florida['time_normalizado'])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Normalizamos la columna time creando la columna time_normalizado con la fecha en el formato %d/%m/%y %H:%M:%S \n",
    "times = [] \n",
    "for data in df_florida['time']/1000 :\n",
    "    times.append(datetime.datetime.utcfromtimestamp(data).strftime('%d/%m/%y %H:%M:%S'))\n",
    "df_florida['time_normalizado']=times\n",
    "\n",
    "# Cambiamos el valor de la columna time_normalizado de object a datetime \n",
    "df_florida['time_normalizado'] = pd.to_datetime(df_florida['time_normalizado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                    float64\n",
       "time                         int64\n",
       "rating                       int64\n",
       "text                        object\n",
       "gmap_id                     object\n",
       "time_normalizado    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos el cambio \n",
    "df_florida.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos las reseñas de 2014 en adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer el año de la columna \"time_normalizado\" y crear una nueva columna \"year\"\n",
    "df_florida[\"year\"] = df_florida[\"time_normalizado\"].dt.year\n",
    "\n",
    "# Valores que deseas conservar en la columna \"year\"\n",
    "valores_a_mantener = [2014, 2015, 2016 , 2017, 2018 , 2019 , 2020 , 2021]\n",
    "\n",
    "# Eliminar los valores de la columna \"year\" que no están en la lista de valores_a_mantener\n",
    "df_florida = df_florida[df_florida[\"year\"].isin(valores_a_mantener)]\n",
    "\n",
    "# Eliminamos la columna year\n",
    "df_florida = df_florida.drop(['year'],axis=1)\n",
    "\n",
    "# Eliminamos la columna time\n",
    "df_florida = df_florida.drop(['time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambio el nombre de la columna gmap_id a business_id y time_normalizado a date\n",
    "df_florida.rename(columns={'gmap_id': 'business_id', 'time_normalizado': 'timestamp'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sebas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas de procesamiento de texto y análisis de sentimiento\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Inicializar el analizador de sentimientos\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para asignar valores según la escala de sentimiento\n",
    "def obtener_puntuacion_sentimiento(texto):\n",
    "    if pd.isnull(texto) or texto == '':\n",
    "        return 1  # Devolver neutral si está vacío o es NaN\n",
    "    elif isinstance(texto, str):\n",
    "        sentimiento = sia.polarity_scores(texto)\n",
    "        puntuacion_compuesta = sentimiento['compound']\n",
    "        if puntuacion_compuesta >= -0.05:\n",
    "            return 2  # Buena puntuación\n",
    "        elif puntuacion_compuesta <= -0.05:\n",
    "            return 0  # Mala puntuación\n",
    "        else:\n",
    "            return 1\n",
    "    else: \n",
    "        return 1  # Devolver neutral para valores que no son str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'text' a cadena de texto\n",
    "df_florida['text'] = df_florida['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función obtener_puntuacion_sentimiento a la columna 'text'\n",
    "df_florida['sentiment_analysis'] = df_florida['text'].apply(obtener_puntuacion_sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna 'text' ya que no la necesitamos con 'sentiment_analysis'\n",
    "df_florida = df_florida.drop(columns=['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>business_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.014719e+20</td>\n",
       "      <td>1</td>\n",
       "      <td>0x8893863ea87bd5dd:0x9383ebf973e74abb</td>\n",
       "      <td>2021-03-08 15:07:30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.154772e+20</td>\n",
       "      <td>5</td>\n",
       "      <td>0x8893863ea87bd5dd:0x9383ebf973e74abb</td>\n",
       "      <td>2020-07-18 00:13:37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  rating                            business_id  \\\n",
       "0  1.014719e+20       1  0x8893863ea87bd5dd:0x9383ebf973e74abb   \n",
       "1  1.154772e+20       5  0x8893863ea87bd5dd:0x9383ebf973e74abb   \n",
       "\n",
       "            timestamp  sentiment_analysis  \n",
       "0 2021-03-08 15:07:30                   0  \n",
       "1 2020-07-18 00:13:37                   0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chequeamos los resultados\n",
    "df_florida.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91766, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chequeamos tamaño del dataset\n",
    "df_florida.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos el df en formato csv\n",
    "df_florida.to_csv('review.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
